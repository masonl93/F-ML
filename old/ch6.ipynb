{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: clean up markdown, is 6.5 correct???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1\n",
    "By randomly sampling with replacement, we are building sub-samples from the sample data with slightly different distributions of the variables. Sampling without replacement would lead to higher variance.   \n",
    "If we select a card from a deck, and then replace it and select a second card, the first one doesn't effect the probability of the second one so the covariance b/w the two is 0. If sampling w/o replacement, the two selections are not independent i.e. the covariance is not 0. We want the probability distribution of selecting features to acutally reflect that of the population and not overfit.  \n",
    "If our dataset was infinite size, than we could sample without replacement but since this is not possible, our finite dataset will always be overfit, or higher variance if we don't sample with replacement.  \n",
    "Ref: https://web.ma.utexas.edu/users/parker/sampling/repl.htm\n",
    "\n",
    "\n",
    "#### 6.2\n",
    "a) With low uniqueness/high overlap, bagging will be less-prone to overfitting than a single classifier, yet it will still be overfit as for example for random forest, it will be a large number of very similar trees that are all overfit. (pg 98)  \n",
    "b) OOB accuracy will be largely inflated as random samlping with replacement will place samples in training set that is very similar (very similar due to financial data having lots of redundant observations) to out of bag. Hence not very reliable in financial applications (pg.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "y = pd.Series(iris.target)\n",
    "X = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_clf = DecisionTreeClassifier(criterion='entropy', max_features='auto', class_weight='balanced')\n",
    "dt_clf = DecisionTreeClassifier(max_features='auto')\n",
    "bag_clf = BaggingClassifier(base_estimator=dt_clf, n_estimators=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "for (i, t),p in zip(y_test.iteritems(), y_pred):\n",
    "    if t != p:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_clf = RandomForestClassifier(n_estimators=1000, class_weight='balanced_subsample', criterion='entropy')\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "for (i, t),p in zip(y_test.iteritems(), y_pred):\n",
    "    if t != p:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3\n",
    "Predicitions above are the same so not a good example. Regardless, the main difference between a bagging classifier/ensemble of decision trees to a random forest classifier is that the random forest has a second level of randomness (first being input data randomly subsampled w/ replacement): subsampling the features at each node split (w/o replacement).  \n",
    "Sklearn's deafult max_features for RandomForestClassifier sqrt(n_features) or 2 features for our 4 feature iris dataset. Therefore, if we create the decision tree classifier like so: DecisionTreeClassifier(max_features='auto'), where max_features='auto', then it too will use sqrt(n_features) or two. This should perform identical to random forest.  \n",
    "Ref: https://quantdare.com/random-forest-many-are-better-than-one/  \n",
    "(pg. 98)  \n",
    "\n",
    "### 6.4\n",
    "a) Suppose we want to use the minimum number of trees in a random forest to achieve some accuracy. Since increasing the number of trees will always improve predicitions (no overfitting as it's average of all trees), we can then decrease number of feautres which leads to lower correlation among tree hence increasing forest accuracy as a whole. On the other hand, increasing number of features will increase a decision trees performance. In conclusion, we need the number of features to increase as number of trees decrease.  \n",
    "b) Yes, if the number of trees are too small and features too larges, then some features might be completely missed in the subspaces, which would hurt accuracy.  \n",
    "c) Since additional trees never hurt random forest's predictive power, just genralizes more, then there is no harm even when number of observations is small. There might not be much benefit since the the small sample size will be generalized over and over, but the number of trees can't hurt regardless how high it is.  \n",
    "Ref: https://stats.stackexchange.com/questions/36165/does-the-optimal-number-of-trees-in-a-random-forest-depend-on-the-number-of-pred  \n",
    "https://datascience.stackexchange.com/questions/13323/minimum-number-of-trees-for-random-forest-classifier  \n",
    "https://datascience.stackexchange.com/questions/23666/how-many-features-to-sample-using-random-forests  \n",
    "\n",
    "### 6.5\n",
    "Stratified k-fold cross-validation is cross-validation but instead of splitting randomly into k folds, we attempt to rearrange the data so it is respresentative of the whole data set (e.g. if each class comprises 50% of the data, then we want to arrange the folds so that each class is 50%). Out of bag accuracy tests data points on trees in which that sample was not used in the training of that tree. Therefore, out of bag is attempting to test how accurate individual trees are on data it has never seen while stratified k-fold cross-validation tests data that the trees have seen before.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
